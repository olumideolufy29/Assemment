{"cells":[{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5332822b-953e-4db2-a0b5-ed4b4c61d1d6"},{"cell_type":"code","source":["import pyspark\n","from pyspark.sql import SparkSession\n","from itertools import chain\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","import pyspark.sql.functions as F\n","from pyspark.sql.functions import col, expr, substring, create_map, lit, when"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.324213Z","session_start_time":"2024-09-06T06:26:22.9783093Z","execution_start_time":"2024-09-06T06:26:32.3684156Z","execution_finish_time":"2024-09-06T06:26:34.5977651Z","parent_msg_id":"74b65999-36eb-4f7d-aca3-bb7340d80a5f"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"09da395a-9b22-44fd-8680-69b75eadd70c"},{"cell_type":"code","source":["\n","spark = SparkSession.builder.appName(\"DataAnalysisAssessment\").getOrCreate()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.3402363Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:35.00929Z","execution_finish_time":"2024-09-06T06:26:35.2608449Z","parent_msg_id":"be558d50-cd4f-43e7-b00c-0cc5d5c2a732"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"385eeb32-9a82-49ef-bce8-bdfd043ec614"},{"cell_type":"code","source":["# Define the schema with metadata\n","schema = StructType([\n","    StructField(\"HRHHID\", StringType(), nullable=True, metadata={\"description\": \"Household Identifier (Part 1)\"}),\n","    StructField(\"HRHHID2\", StringType(), nullable=True, metadata={\"description\": \"Household Identifier (Part 2)\"}),\n","    StructField(\"QSTNUM\", StringType(), nullable=True, metadata={\"description\": \"Unique Household Identifier (Valid only within a specific month)\"}),\n","    StructField(\"HRMONTH\", StringType(), nullable=True, metadata={\"description\": \"Month of Interview\"}),\n","    StructField(\"HRYEAR4\", StringType(), nullable=True, metadata={\"description\": \"Year of Interview\"}),\n","    StructField(\"HUFINAL\", StringType(), nullable=True, metadata={\"description\": \"Final Outcome Code\"}),\n","    StructField(\"HEHOUSUT\", StringType(), nullable=True, metadata={\"description\": \"Type of Housing Unit\"}),\n","    StructField(\"HRHTYPE\", StringType(), nullable=True, metadata={\"description\": \"Household Type\"}),\n","    StructField(\"HETELHHD\", StringType(), nullable=True, metadata={\"description\": \"Is there a telephone in this house/apartment?\"}),\n","    StructField(\"HETELAVL\", StringType(), nullable=True, metadata={\"description\": \"Is there a telephone elsewhere which people in this household can be contacted?\"}),\n","    StructField(\"HEPHONEO\", StringType(), nullable=True, metadata={\"description\": \"Is a telephone interview acceptable?\"}),\n","    StructField(\"HUINTTYP\", StringType(), nullable=True, metadata={\"description\": \"Type of Interview\"}),\n","    StructField(\"HEFAMINC\", StringType(), nullable=True, metadata={\"description\": \"Family Income\"}),\n","    StructField(\"GEREG\", StringType(), nullable=True, metadata={\"description\": \"Region\"}),\n","    StructField(\"GEDIV\", StringType(), nullable=True, metadata={\"description\": \"Division\"}),\n","    StructField(\"PTDTRACE\", StringType(), nullable=True, metadata={\"description\": \"Race\"})\n","])\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.3409165Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:35.7982983Z","execution_finish_time":"2024-09-06T06:26:36.0683265Z","parent_msg_id":"ebb1d45d-4848-4dc0-9d57-d22728845cec"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e1c3538e-f00c-4df1-be7b-018644a68a5a"},{"cell_type":"code","source":["# Datapath\n","\n","data_path = \"./data/dec17pub.dat\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.3414782Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:36.4760481Z","execution_finish_time":"2024-09-06T06:26:36.7064632Z","parent_msg_id":"601f40f7-f805-4194-9866-e9003d9c17e4"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0fff721b-f2ca-4bde-a721-ec39b2496e25"},{"cell_type":"code","source":["\n","# importing the zipfile module \n","from zipfile import ZipFile \n","\n","try:\n","    # loading the temp.zip and creating a zip object \n","    with ZipFile(\"./data/dec17pub.zip\", 'r') as zObject: \n","    \n","        # Extracting all the members of the zip  \n","        # into a specific location. \n","        zObject.extractall( \n","            path=\"data_path\") \n","except:\n","    pass"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3c175f22-be42-409d-9dd1-6ed7d8e41fcc"},{"cell_type":"code","source":["def strim_cols(df: pyspark.sql.DataFrame)->pyspark.sql.DataFrame:\n","    \"\"\"\n","    Trim leading and trailing whitespace from all string columns in the DataFrame.\n","\n","    This function iterates over all columns in the DataFrame and applies the `trim` function to\n","    columns that are of string type. Leading and trailing whitespace characters are removed from\n","    the values in these columns. Columns that are not of string type are left unchanged.\n","\n","    Parameters:\n","    ----------\n","    df : DataFrame\n","        The input DataFrame on which the trimming operation is to be performed.\n","\n","    Returns:\n","    -------\n","    DataFrame\n","        A new DataFrame with leading and trailing whitespace removed from all string columns.\n","\n","    \"\"\"    \n","    for column in df.columns:\n","        df = df.withColumn(column, F.trim(column))\n","\n","    return df\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.3420655Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:37.1171395Z","execution_finish_time":"2024-09-06T06:26:37.3589398Z","parent_msg_id":"cf0bb86e-8bcf-4a8e-9e0b-701b6fbbf6ed"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0b745fc-ceaf-4512-bc4d-2f1dbecdee82"},{"cell_type":"code","source":["def load_data(data_path: str = data_path)->pyspark.sql.DataFrame:\n","    \"\"\"----------\n","    data_path : str\n","        The path to the CSV file that contains the raw data.\n","\n","    Returns:\n","    -------\n","    DataFrame\n","        A Spark DataFrame with the following columns extracted and renamed:\n","        - 'HRHHID': Household Identifier (Part 1) - Extracted from characters 1 to 15.\n","        - 'HRHHID2': Household Identifier (Part 2) - Extracted from characters 71 to 75.\n","        - 'QSTNUM': Unique Household Identifier - Extracted from characters 815 to 819.\n","        - 'HRMONTH': Month of Interview - Extracted from characters 16 to 17.\n","        - 'HRYEAR4': Year of Interview - Extracted from characters 18 to 21.\n","        - 'HUFINAL': Final Outcome Code - Extracted from characters 24 to 26.\n","        - 'HEHOUSUT': Type of Housing Unit - Extracted from characters 31 to 32.\n","        - 'HRHTYPE': Household Type - Extracted from characters 61 to 62.\n","        - 'HETELHHD': Is There a Telephone in This House/Apartment? - Extracted from characters 33 to 34.\n","        - 'HETELAVL': Is There a Telephone Elsewhere on Which People in This Household Can Be Contacted? - Extracted from characters 35 to 36.\n","        - 'HEPHONEO': Is a Telephone Interview Acceptable? - Extracted from characters 37 to 38.\n","        - 'HUINTTYP': Type of Interview - Extracted from characters 65 to 66.\n","        - 'HEFAMINC': Family Income - Extracted from characters 39 to 40.\n","        - 'GEREG': Region - Extracted from characters 89 to 90.\n","        - 'GEDIV': Division - Extracted from character 91.\n","        - 'PTDTRACE': Race - Extracted from characters 139 to 140.\n","\n","    Notes:\n","    -----\n","    - The function assumes that the fat file contains a single column named '_c0' with concatenated raw data.\n","    - The function drops the original raw column '_c0' after extracting the relevant substrings.\n","    - The function requires a Spark session to be active for reading and processing the data.\n","    \"\"\"\n","\n","    df = spark.read.format(\"csv\").load(data_path)\n","    df = df.withColumn(\"HRHHID\", substring(\"_c0\", 1, 15))\n","    df = df.withColumn(\"HRHHID2\", substring(\"_c0\", 71, 5))\n","    df = df.withColumn(\"QSTNUM\", substring(\"_c0\", 815, 5))\n","    df = df.withColumn(\"HRMONTH\", substring(\"_c0\", 16, 2))\n","    df = df.withColumn(\"HRYEAR4\", substring(\"_c0\", 18, 4))\n","    df = df.withColumn(\"HUFINAL\", substring(\"_c0\", 24, 3))\n","    df = df.withColumn(\"HEHOUSUT\", substring(\"_c0\", 31, 2))\n","    df = df.withColumn(\"HRHTYPE\", substring(\"_c0\", 61, 2))\n","    df = df.withColumn(\"HETELHHD\", substring(\"_c0\", 33, 2))\n","    df = df.withColumn(\"HETELAVL\", substring(\"_c0\", 35, 2))\n","    df = df.withColumn(\"HEPHONEO\", substring(\"_c0\", 37, 2))\n","    df = df.withColumn(\"HUINTTYP\", substring(\"_c0\", 65, 2))\n","    df = df.withColumn(\"HEFAMINC\", substring(\"_c0\", 39, 2))\n","    df = df.withColumn(\"GEREG\", substring(\"_c0\", 89, 2))\n","    df = df.withColumn(\"GEDIV\", substring(\"_c0\", 91, 1))\n","    df = df.withColumn(\"PTDTRACE\", substring(\"_c0\", 139, 2))\n","\n","    # Drop the raw column\n","    df = df.drop(\"_c0\")\n","\n","    return  strim_cols(df)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5243054Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:37.7814285Z","execution_finish_time":"2024-09-06T06:26:38.037927Z","parent_msg_id":"3a6230cb-ffa4-4372-9628-f111ed2f1e43"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b0a4669d-6a60-40d6-95fd-be15522192ba"},{"cell_type":"code","source":["# income range mapping\n","income_range_mapping = {\n","    \"1\": \"Less $5,000\",\n","    \"2\": \"$5,000 - $7,499\",\n","    \"3\": \"$7,500 - $9,999\",\n","    \"4\": \"$10,000 - $12,499\",\n","    \"5\": \"$12,500 - $14,999\",\n","    \"6\": \"$15,000 - $19,999\",\n","    \"7\": \"$20,000 - $24,999\",\n","    \"8\": \"$25,000 - $29,999\",\n","    \"9\": \"$30,000 - $34,999\",\n","    \"10\": \"$35,000 - $39,999\",\n","    \"11\": \"$40,000 - $49,999\",\n","    \"12\": \"$50,000 - $59,999\",\n","    \"13\": \"$60,000 - $74,999\",\n","    \"14\": \"$75,000 - $99,999\",\n","    \"15\": \"$100,000 - $149,999\",\n","    \"16\": \"$150,000 or more\"\n","}\n","\n","# Define the division mapping\n","division_mapping = {\n","    \"1\": \"New England\",\n","    \"2\": \"Middle Atlantic\",\n","    \"3\": \"East North Central\",\n","    \"4\": \"West North Central\",\n","    \"5\": \"South Atlantic\",\n","    \"6\": \"East South Central\",\n","    \"7\": \"West South Central\",\n","    \"8\": \"Mountain\",\n","    \"9\": \"Pacific\"\n","}\n","\n","# Define the race mapping\n","race_mapping = {\n","    \"1\": \"White Only\",\n","    \"2\": \"Black Only\",\n","    \"3\": \"American Indian, Alaskan Native Only\",\n","    \"4\": \"Asian Only\",\n","    \"5\": \"Hawaiian/Pacific Islander Only\",\n","    \"6\": \"White-Black\",\n","    \"7\": \"White-AI\",\n","    \"8\": \"White-Asian\",\n","    \"9\": \"White-HP\",\n","    \"10\": \"Black-AI\",\n","    \"11\": \"Black-Asian\",\n","    \"12\": \"Black-HP\",\n","    \"13\": \"AI-Asian\",\n","    \"14\": \"AI-HP\",\n","    \"15\": \"Asian-HP\",\n","    \"16\": \"W-B-AI\",\n","    \"17\": \"W-B-A\",\n","    \"18\": \"W-B-HP\",\n","    \"19\": \"W-AI-A\",\n","    \"20\": \"W-AI-HP\",\n","    \"21\": \"W-A-HP\",\n","    \"22\": \"B-AI-A\",\n","    \"23\": \"W-B-AI-A\",\n","    \"24\": \"W-AI-A-HP\",\n","    \"25\": \"Other 3 Race Combinations\",\n","    \"26\": \"Other 4 and 5 Race Combinations\"\n","}\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.531741Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:38.4057209Z","execution_finish_time":"2024-09-06T06:26:38.6605562Z","parent_msg_id":"cc7579a4-59f4-4828-bb49-9dd70c637df0"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fd1fb6b3-351a-4f84-901b-0063169beaeb"},{"cell_type":"markdown","source":["# Mapper"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"61060aa7-752b-4e4e-9984-048d91fda481"},{"cell_type":"code","source":["# defmapper(df):Mapp\n","    # return df.withColumn(c, when(df[c].isin(list(race_mapping.keys())),  df[c]).otherwise('Others'))\n","\n","def Mapper(df:pyspark.sql.DataFrame, column_name:str , dict_mapper:dict):\n","\n","    \"\"\"\n","     Trim leading and trailing whitespace from all string columns in the DataFrame.\n","\n","    This function iterates over all columns in the DataFrame and applies the `trim` function to\n","    columns that are of string type. Leading and trailing whitespace characters are removed from\n","    the values in these columns. Columns that are not of string type are left unchanged.\n","\n","    Parameters:\n","    ----------\n","    df : DataFrame\n","        The input DataFrame on which the trimming operation is to be performed.\n","\n","    Returns:\n","    -------\n","    DataFrame\n","        A new DataFrame with leading and trailing whitespace removed from all string columns.\n","\n","    \"\"\"\n","    # Convert the dictionary into a Spark DataFrame for the mapping\n","    cols = df.columns\n","    mapping_df = spark.createDataFrame(dict_mapper.items(), [\"code\", \"value\"])\n","\n","    # Join the original DataFrame with the mapping DataFrame\n","    df2 = df.join(mapping_df, df[column_name] == mapping_df[\"code\"], \"left\")\n","\n","    # Replace null values with 'Others' for unmatched codes\n","    df2 = df2.withColumn(column_name, when(col(\"value\").isNull(), 'Others').otherwise(col(\"value\")))\n","\n","    df2 = df2.select(cols)\n","\n","    return df2    "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5325025Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:39.0474745Z","execution_finish_time":"2024-09-06T06:26:39.3071306Z","parent_msg_id":"6d998e0d-9c2d-4c64-961f-42ba6c0eb6c3"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"22e232ba-0858-4265-9b20-f28b434c8dc7"},{"cell_type":"markdown","source":["# LOad dataset from the source"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3ae458e8-5443-4fa0-859c-a74c8b47c3b6"},{"cell_type":"code","source":["df = load_data(data_path)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5332145Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:39.7907846Z","execution_finish_time":"2024-09-06T06:26:42.2711939Z","parent_msg_id":"8886f31e-3893-40f7-804a-d119e1cde943"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"34212acc-09e4-4c3f-9629-b9df81ce16d6"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0277bd3a-ade2-459b-a986-a2ce21f8a65e"},{"cell_type":"markdown","source":["# Income Range by responders\n","\n","\n","\n","    Mapping Definition: The income_range_mapping dictionary provides a mapping from the numeric income codes to their descriptive ranges.\n","\n","    Transform Data: Using expr in PySpark, we create a new column FamilyIncomeRange based on the HEFAMINC column values.\n","\n","    Group and Count: We then group the DataFrame by the FamilyIncomeRange column and count the occurrences.\n","\n","    Display Results: Finally, the results are ordered and displayed to show the count of responders per income range.\n","\n","    This will give you a clear count of responders across each defined income range, making the data more interpretable.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e7c59a00-c9d9-4b10-857e-272b8c2c13ad"},{"cell_type":"code","source":["column_name = 'HEFAMINC'\n","\n","\n","income_mapped = Mapper(df, column_name, income_range_mapping)\n","\n","income_counts = income_mapped.groupBy(column_name).count().orderBy('count', ascending = False)\n","\n","income_counts = income_counts.withColumnRenamed('coumt', 'IncomeCount')\n","income_counts.show(truncate=False)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5338889Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:42.7063354Z","execution_finish_time":"2024-09-06T06:26:47.632962Z","parent_msg_id":"692031c7-dc99-4587-bf0f-01187631e255"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------------------+-----+\n|HEFAMINC           |count|\n+-------------------+-----+\n|Others             |20391|\n|$100,000 - $149,999|17794|\n|$75,000 - $99,999  |16557|\n|$150,000 or more   |15704|\n|$60,000 - $74,999  |13442|\n|$50,000 - $59,999  |9971 |\n|$40,000 - $49,999  |9788 |\n|$30,000 - $34,999  |6743 |\n|$35,000 - $39,999  |6620 |\n|$20,000 - $24,999  |6312 |\n|$25,000 - $29,999  |5803 |\n|$15,000 - $19,999  |4518 |\n|$10,000 - $12,499  |3161 |\n|Less $5,000        |3136 |\n|$12,500 - $14,999  |2614 |\n|$7,500 - $9,999    |2277 |\n|$5,000 - $7,499    |1625 |\n+-------------------+-----+\n\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"73172d7f-1e4b-4b46-8887-024dcc5f54a6"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"732b2c28-70a7-4e94-b4e5-6ce3f956e50d"},{"cell_type":"markdown","source":["# TOP 10 count of responders per geographical division/location and race    \n","    \n","    Mappings: Define mappings for geographical divisions and races.\n","\n","    Transform Data: Use expr to create new columns GeographicalDivision and Race with their descriptive names based on encoded values.\n","\n","    Group and Count: Group the DataFrame by GeographicalDivision and Race, then count the occurrences.\n","\n","    Display Results: The show(10, truncate=False) function displays the top 10 results without truncating the output, so you can see the full names.\n","\n","    This will provide a detailed view of the number of responders grouped by geographical division and race, with meaningful names rather than encoded values."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f07f20c9-764d-410a-8adf-fd13dd258905"},{"cell_type":"code","source":["divivsion_race_columns = {\"GEDIV\":division_mapping, \"PTDTRACE\": race_mapping}\n","\n","division_race = df.select(\"HRHHID\", \"PTDTRACE\", \"GEDIV\")\n","\n","\n","division_race_counts = division_race.groupBy(\"GEDIV\", \"PTDTRACE\").count()\n","\n","division_race_counts = Mapper(division_race_counts, \"PTDTRACE\", race_mapping)\n","\n","division_race_counts = Mapper(division_race_counts, \"GEDIV\", division_mapping)\n","\n","\n","division_race_counts.orderBy(\"count\", ascending=False).show(10)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5345716Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:48.0991649Z","execution_finish_time":"2024-09-06T06:26:51.6701851Z","parent_msg_id":"6ae2a37a-74f6-4018-ab90-64c8e17590cb"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+------------------+----------+-----+\n|             GEDIV|  PTDTRACE|count|\n+------------------+----------+-----+\n|    South Atlantic|White Only|16999|\n|          Mountain|White Only|14343|\n|           Pacific|White Only|13214|\n|East North Central|White Only|11325|\n|West South Central|White Only|11248|\n|West North Central|White Only| 9884|\n|   Middle Atlantic|White Only| 8487|\n|       New England|White Only| 8410|\n|East South Central|White Only| 6580|\n|    South Atlantic|Black Only| 4899|\n+------------------+----------+-----+\nonly showing top 10 rows\n\n"]}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b80462e-82af-46af-bc39-0b23bc3b2205"},{"cell_type":"markdown","source":["# Count of Responders with No Home Telephone but Access to Telephone Elsewhere and Accepting Telephone Interviews\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cf5049c8-6000-4052-b705-1fa200b2f84b"},{"cell_type":"code","source":["telephone_access_counts = df.filter(\n","    (col(\"HETELHHD\") == \"2\") &  # No telephone in house\n","    (col(\"HETELAVL\") == \"1\") &  # Telephone elsewhere\n","    (col(\"HEPHONEO\") == \"1\")    # Telephone interview accepted\n",").count()\n","\n","print(f\"Number of responders without telephone at home but can access telephone elsewhere and accept telephone interview: {telephone_access_counts}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.5352592Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:52.0694371Z","execution_finish_time":"2024-09-06T06:26:53.7118094Z","parent_msg_id":"abefe345-7963-4151-a834-032d7a723661"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of responders without telephone at home but can access telephone elsewhere and accept telephone interview: 633\n"]}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f2309b40-b330-44d6-9fb0-c86d28affd6f"},{"cell_type":"markdown","source":["# Number of responders who can access a telephone but telephone interview is not accepted"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c57fe3ef-ce90-4d44-a51f-5b5a164bf503"},{"cell_type":"code","source":["telephone_no_interview_counts = df.filter(\n","    (col(\"HETELHHD\") == \"1\") &  # Telephone in house\n","    (col(\"HEPHONEO\") == \"2\")    # Telephone interview not accepted\n",").count()\n","\n","print(f\"Number of responders who can access a telephone but telephone interview is not accepted: {telephone_no_interview_counts}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"050ec653-b802-4622-a117-fb16475f7f2e","normalized_state":"finished","queued_time":"2024-09-06T06:26:22.535965Z","session_start_time":null,"execution_start_time":"2024-09-06T06:26:54.1560654Z","execution_finish_time":"2024-09-06T06:26:55.6873991Z","parent_msg_id":"8780203e-16a0-4c4a-a57d-c94efcb51de7"},"text/plain":"StatementMeta(, 050ec653-b802-4622-a117-fb16475f7f2e, 15, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of responders who can access a telephone but telephone interview is not accepted: 0\n"]}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2675c459-1926-4032-9141-058b2bae6aaa"}],"metadata":{"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"40de504b-4c02-4a17-b1c4-e98703e06e4e","default_lakehouse_name":"Loanlakehouse","default_lakehouse_workspace_id":"740efc07-b953-4852-9dcc-4f34c5feb44b"}}},"nbformat":4,"nbformat_minor":5}